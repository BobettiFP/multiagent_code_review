{"record_format_version": 6, "code": "\n        python scripts/runner.py           --task {input.task}           --model {params.model}           --config {params.cfg}           --out {output}\n        ", "rule": "run_eval", "input": ["data/tasks/HumanEval_147.json"], "log": [], "params": ["'MULTI'", "'gpt-4o'"], "shellcmd": "\n        python scripts/runner.py           --task data/tasks/HumanEval_147.json           --model gpt-4o           --config MULTI           --out raw_results/MULTI/HumanEval_147.json\n        ", "incomplete": false, "starttime": 1747763327.4973104, "endtime": 1747763368.108817, "job_hash": 274603103, "conda_env": null, "software_stack_hash": "d41d8cd98f00b204e9800998ecf8427e", "container_img_url": null, "input_checksums": {"data/tasks/HumanEval_147.json": "9750580e1169adfc92e66bb5ecc32c2fa307fc5e084192ab20e37ccf4f2da69f"}}