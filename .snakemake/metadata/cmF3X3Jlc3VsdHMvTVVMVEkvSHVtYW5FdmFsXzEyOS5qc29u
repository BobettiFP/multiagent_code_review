{"record_format_version": 6, "code": "\n        python scripts/runner.py             --task {input.task}             --model {params.model}             --config {wildcards.config}             --out {output}\n        ", "rule": "run_eval", "input": ["data/tasks/HumanEval_129.json"], "log": [], "params": ["'gpt-4o'"], "shellcmd": "\n        python scripts/runner.py             --task data/tasks/HumanEval_129.json             --model gpt-4o             --config MULTI             --out raw_results/MULTI/HumanEval_129.json\n        ", "incomplete": false, "starttime": 1747760474.7951143, "endtime": 1747760519.188102, "job_hash": 273952523, "conda_env": null, "software_stack_hash": "d41d8cd98f00b204e9800998ecf8427e", "container_img_url": null, "input_checksums": {"data/tasks/HumanEval_129.json": "e3ca70301c0c0e614e9d6f12dc902cd88aa3af76e5b46dfa349eefca7f8d030c"}}